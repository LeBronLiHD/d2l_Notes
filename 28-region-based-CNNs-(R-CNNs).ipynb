{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e804cba",
   "metadata": {},
   "source": [
    "# Region-based CNNs (R-CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427b3ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "X = torch.arange(16.).reshape(1, 1, 4, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8f0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = torch.Tensor([[0, 0, 0, 20, 20], [0, 0, 10, 30, 30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1421c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a53314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\VOCtrainval_11-May-2012.tar from http://d2l-data.s3-accelerate.amazonaws.com/VOCtrainval_11-May-2012.tar...\n"
     ]
    },
    {
     "ename": "ReadError",
     "evalue": "unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#@save\u001b[39;00m\n\u001b[0;32m      2\u001b[0m d2l\u001b[38;5;241m.\u001b[39mDATA_HUB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoc2012\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (d2l\u001b[38;5;241m.\u001b[39mDATA_URL \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVOCtrainval_11-May-2012.tar\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4e443f8a2eca6b1dac8a6c57641b67dd40621a49\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m voc_dir \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvoc2012\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVOCdevkit/VOC2012\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\d2l\\torch.py:426\u001b[0m, in \u001b[0;36mdownload_extract\u001b[1;34m(name, folder)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly zip/tar files can be extracted.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 426\u001b[0m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, folder) \u001b[38;5;28;01mif\u001b[39;00m folder \u001b[38;5;28;01melse\u001b[39;00m data_dir\n",
      "File \u001b[1;32mF:\\Python399\\lib\\tarfile.py:2036\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[1;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[0;32m   2034\u001b[0m         tarinfo\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0o700\u001b[39m\n\u001b[0;32m   2035\u001b[0m     \u001b[38;5;66;03m# Do not set_attrs directories, as we will do that further down\u001b[39;00m\n\u001b[1;32m-> 2036\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2037\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2039\u001b[0m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[0;32m   2040\u001b[0m directories\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mF:\\Python399\\lib\\tarfile.py:2077\u001b[0m, in \u001b[0;36mTarFile.extract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     tarinfo\u001b[38;5;241m.\u001b[39m_link_target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, tarinfo\u001b[38;5;241m.\u001b[39mlinkname)\n\u001b[0;32m   2076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2077\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrorlevel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mF:\\Python399\\lib\\tarfile.py:2150\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbg(\u001b[38;5;241m1\u001b[39m, tarinfo\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[1;32m-> 2150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[0;32m   2152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedir(tarinfo, targetpath)\n",
      "File \u001b[1;32mF:\\Python399\\lib\\tarfile.py:2199\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2197\u001b[0m     target\u001b[38;5;241m.\u001b[39mtruncate()\n\u001b[0;32m   2198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReadError\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Python399\\lib\\tarfile.py:249\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    247\u001b[0m     buf \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mread(bufsize)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m bufsize:\n\u001b[1;32m--> 249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m     dst\u001b[38;5;241m.\u001b[39mwrite(buf)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remainder \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mReadError\u001b[0m: unexpected end of data"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['voc2012'] = (d2l.DATA_URL + 'VOCtrainval_11-May-2012.tar',\n",
    "                           '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n",
    "\n",
    "voc_dir = d2l.download_extract('voc2012', 'VOCdevkit/VOC2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def read_voc_images(voc_dir, is_train=True):\n",
    "    \"\"\"Read all VOC feature and label images.\"\"\"\n",
    "    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',\n",
    "                             'train.txt' if is_train else 'val.txt')\n",
    "    mode = torchvision.io.image.ImageReadMode.RGB\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [], []\n",
    "    for i, fname in enumerate(images):\n",
    "        features.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'JPEGImages', f'{fname}.jpg')))\n",
    "        labels.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'SegmentationClass' ,f'{fname}.png'), mode))\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = read_voc_images(voc_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb28378",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "imgs = train_features[0:n] + train_labels[0:n]\n",
    "imgs = [img.permute(1,2,0) for img in imgs]\n",
    "d2l.show_images(imgs, 2, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "#@save\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def voc_colormap2label():\n",
    "    \"\"\"Build the mapping from RGB to class indices for VOC labels.\"\"\"\n",
    "    colormap2label = torch.zeros(256 ** 3, dtype=torch.long)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[\n",
    "            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    return colormap2label\n",
    "\n",
    "#@save\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"Map any RGB values in VOC labels to their class indices.\"\"\"\n",
    "    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d943a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = voc_label_indices(train_labels[0], voc_colormap2label())\n",
    "y[105:115, 130:140], VOC_CLASSES[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    \"\"\"Randomly crop both feature and label images.\"\"\"\n",
    "    rect = torchvision.transforms.RandomCrop.get_params(\n",
    "        feature, (height, width))\n",
    "    feature = torchvision.transforms.functional.crop(feature, *rect)\n",
    "    label = torchvision.transforms.functional.crop(label, *rect)\n",
    "    return feature, label\n",
    "\n",
    "imgs = []\n",
    "for _ in range(n):\n",
    "    imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)\n",
    "\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "d2l.show_images(imgs[::2] + imgs[1::2], 2, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    \"\"\"Randomly crop both feature and label images.\"\"\"\n",
    "    rect = torchvision.transforms.RandomCrop.get_params(\n",
    "        feature, (height, width))\n",
    "    feature = torchvision.transforms.functional.crop(feature, *rect)\n",
    "    label = torchvision.transforms.functional.crop(label, *rect)\n",
    "    return feature, label\n",
    "\n",
    "imgs = []\n",
    "for _ in range(n):\n",
    "    imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)\n",
    "\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "d2l.show_images(imgs[::2] + imgs[1::2], 2, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948da4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class VOCSegDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the VOC dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, is_train, crop_size, voc_dir):\n",
    "        self.transform = torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.crop_size = crop_size\n",
    "        features, labels = read_voc_images(voc_dir, is_train=is_train)\n",
    "        self.features = [self.normalize_image(feature)\n",
    "                         for feature in self.filter(features)]\n",
    "        self.labels = self.filter(labels)\n",
    "        self.colormap2label = voc_colormap2label()\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        return self.transform(img.float() / 255)\n",
    "\n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[1] >= self.crop_size[0] and\n",
    "            img.shape[2] >= self.crop_size[1])]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n",
    "                                       *self.crop_size)\n",
    "        return (feature, voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ee2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (320, 480)\n",
    "voc_train = VOCSegDataset(True, crop_size, voc_dir)\n",
    "voc_test = VOCSegDataset(False, crop_size, voc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0689806",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_iter = torch.utils.data.DataLoader(voc_train, batch_size, shuffle=True,\n",
    "                                    drop_last=True,\n",
    "                                    num_workers=d2l.get_dataloader_workers())\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_voc(batch_size, crop_size):\n",
    "    \"\"\"Load the VOC semantic segmentation dataset.\"\"\"\n",
    "    voc_dir = d2l.download_extract('voc2012', os.path.join(\n",
    "        'VOCdevkit', 'VOC2012'))\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(True, crop_size, voc_dir), batch_size,\n",
    "        shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(False, crop_size, voc_dir), batch_size,\n",
    "        drop_last=True, num_workers=num_workers)\n",
    "    return train_iter, test_iter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
